{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30840,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "__tE4n2VEhph",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:43:33.151306Z",
          "iopub.execute_input": "2025-01-17T09:43:33.152159Z",
          "iopub.status.idle": "2025-01-17T09:43:36.479730Z",
          "shell.execute_reply.started": "2025-01-17T09:43:33.152109Z",
          "shell.execute_reply": "2025-01-17T09:43:36.478660Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "id": "J1W5_sJPuPYU",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:43:40.390017Z",
          "iopub.execute_input": "2025-01-17T09:43:40.390320Z",
          "iopub.status.idle": "2025-01-17T09:43:43.695858Z",
          "shell.execute_reply.started": "2025-01-17T09:43:40.390289Z",
          "shell.execute_reply": "2025-01-17T09:43:43.694780Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"community-datasets/offenseval_dravidian\", \"tamil\")\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "MX6RAU53sUlf",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:43:48.335680Z",
          "iopub.execute_input": "2025-01-17T09:43:48.335979Z",
          "iopub.status.idle": "2025-01-17T09:43:57.328142Z",
          "shell.execute_reply.started": "2025-01-17T09:43:48.335952Z",
          "shell.execute_reply": "2025-01-17T09:43:57.327190Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"community-datasets/offenseval_dravidian\", \"tamil\")\n",
        "\n",
        "# Convert the dataset to a list of dictionaries so train_test_split can be applied\n",
        "train_data = dataset['train']\n",
        "\n",
        "# Convert the dataset to a list of dicts (this step should be done carefully)\n",
        "train_data_list = [{'text': item['text'], 'label': item['label']} for item in train_data]\n",
        "\n",
        "# Split the train data into 90% for training and 10% for testing\n",
        "train_data_split, test_data_split = train_test_split(train_data_list, test_size=0.1, random_state=42)\n",
        "\n",
        "# Clean function to preserve emojis and emoticons\n",
        "def clean_text(text):\n",
        "    # Remove unwanted characters but keep emojis and emoticons\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  # Remove URLs\n",
        "    # Keep only letters, numbers, whitespaces, and emojis\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U000024C2-\\U0001F251]', '', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "# Apply the cleaning function to the train, test, and validation datasets\n",
        "train_data_split = [{'text': clean_text(item['text']), 'label': item['label']} for item in train_data_split]\n",
        "test_data_split = [{'text': clean_text(item['text']), 'label': item['label']} for item in test_data_split]\n",
        "dataset['validation'] = [{'text': clean_text(item['text']), 'label': item['label']} for item in dataset['validation']]\n",
        "\n",
        "# Check the cleaned data\n",
        "print(train_data_split[1])\n",
        "print(test_data_split[0])\n",
        "print(dataset['validation'][0])"
      ],
      "metadata": {
        "id": "L25cyOVXuSf-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:44:02.398359Z",
          "iopub.execute_input": "2025-01-17T09:44:02.398911Z",
          "iopub.status.idle": "2025-01-17T09:44:08.508568Z",
          "shell.execute_reply.started": "2025-01-17T09:44:02.398878Z",
          "shell.execute_reply": "2025-01-17T09:44:08.507696Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"community-datasets/offenseval_dravidian\", \"tamil\")\n",
        "\n",
        "# Extract train data\n",
        "train_data = dataset['train']\n",
        "\n",
        "# Convert to a list of dictionaries for train_test_split\n",
        "train_data_list = [{'text': item['text'], 'label': item['label']} for item in train_data]\n",
        "\n",
        "# Split train data into 90% train and 10% test\n",
        "train_data_split, test_data_split = train_test_split(train_data_list, test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert lists of dictionaries to pandas DataFrames\n",
        "df_train = pd.DataFrame(train_data_split)\n",
        "df_test = pd.DataFrame(test_data_split)\n",
        "df_val = pd.DataFrame([{'text': item['text'], 'label': item['label']} for item in dataset['validation']])\n",
        "\n",
        "# Ensure the DataFrames contain the required columns\n",
        "required_columns = ['text', 'label']\n",
        "for df_name, df in zip(['df_train', 'df_test', 'df_val'], [df_train, df_test, df_val]):\n",
        "    if not all(col in df.columns for col in required_columns):\n",
        "        raise KeyError(f\"{df_name} must contain the columns {required_columns}.\")\n",
        "\n",
        "# Function to extract emojis from the text\n",
        "def extract_emojis(text):\n",
        "    emoji_pattern = re.compile(\n",
        "        r'[\\U0001F600-\\U0001F64F'  # emoticons\n",
        "        r'\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n",
        "        r'\\U0001F680-\\U0001F6FF'  # transport & map symbols\n",
        "        r'\\U0001F700-\\U0001F77F'  # alchemical symbols\n",
        "        r'\\U0001F780-\\U0001F7FF'  # Geometric Shapes Extended\n",
        "        r'\\U0001F800-\\U0001F8FF'  # Supplemental Arrows-C\n",
        "        r'\\U0001F900-\\U0001F9FF'  # Supplemental Symbols and Pictographs\n",
        "        r'\\U0001FA00-\\U0001FA6F'  # Chess Symbols\n",
        "        r'\\U0001FA70-\\U0001FAFF'  # Symbols and Pictographs Extended-A\n",
        "        r'\\U00002702-\\U000027B0'  # Dingbats\n",
        "        r'\\U000024C2-\\U0001F251'  # Enclosed characters\n",
        "        r']+', flags=re.UNICODE)\n",
        "    emojis = emoji_pattern.findall(text)\n",
        "    return ''.join(emojis)\n",
        "\n",
        "# Function to separate emojis and clean text\n",
        "def separate_emojis(text):\n",
        "    emojis = extract_emojis(text)\n",
        "    # Remove emojis and keep only cleaned text\n",
        "    text_without_emojis = re.sub(r'[^\\w\\s,\\.!?]', '', text)\n",
        "    return text_without_emojis.strip(), emojis\n",
        "\n",
        "# Apply the cleaning and emoji extraction function\n",
        "df_train['cleaned_text'], df_train['emojis'] = zip(*df_train['text'].map(separate_emojis))\n",
        "df_test['cleaned_text'], df_test['emojis'] = zip(*df_test['text'].map(separate_emojis))\n",
        "df_val['cleaned_text'], df_val['emojis'] = zip(*df_val['text'].map(separate_emojis))\n",
        "\n",
        "# Create separate DataFrames for cleaned text and emojis with labels\n",
        "df_cleaned_text_train = df_train[['cleaned_text', 'label']].copy()\n",
        "df_emojis_train = df_train[['emojis', 'label']].copy()\n",
        "\n",
        "df_cleaned_text_test = df_test[['cleaned_text', 'label']].copy()\n",
        "df_emojis_test = df_test[['emojis', 'label']].copy()\n",
        "\n",
        "df_cleaned_text_val = df_val[['cleaned_text', 'label']].copy()\n",
        "df_emojis_val = df_val[['emojis', 'label']].copy()\n",
        "\n",
        "# Display sample data\n",
        "print(\"Cleaned Text Train Data:\")\n",
        "print(df_cleaned_text_train.head())\n",
        "\n",
        "print(\"\\nEmojis Train Data:\")\n",
        "print(df_emojis_train.head())\n",
        "\n",
        "print(\"\\nCleaned Text Test Data:\")\n",
        "print(df_cleaned_text_test.head())\n",
        "\n",
        "print(\"\\nEmojis Test Data:\")\n",
        "print(df_emojis_test.head())\n",
        "\n",
        "print(\"\\nCleaned Text Validation Data:\")\n",
        "print(df_cleaned_text_val.head())\n",
        "\n",
        "print(\"\\nEmojis Validation Data:\")\n",
        "print(df_emojis_val.head())"
      ],
      "metadata": {
        "id": "FPJL_RJo3EyS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:44:12.815257Z",
          "iopub.execute_input": "2025-01-17T09:44:12.815861Z",
          "iopub.status.idle": "2025-01-17T09:44:17.906949Z",
          "shell.execute_reply.started": "2025-01-17T09:44:12.815824Z",
          "shell.execute_reply": "2025-01-17T09:44:17.906094Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# Load a pre-trained model and tokenizer\n",
        "model_name = \"bert-base-uncased\"  # Replace with a model fine-tuned for emojis if needed\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Function to get embeddings for emojis\n",
        "def get_emoji_embedding(emojis, tokenizer, model):\n",
        "    if not emojis:  # No emojis provided\n",
        "        return torch.zeros(768)  # Assuming the model outputs 768-dimensional embeddings\n",
        "    inputs = tokenizer(emojis, return_tensors=\"pt\", truncation=True, max_length=10)\n",
        "    outputs = model(**inputs)\n",
        "    # Use the mean of the last hidden state as the embedding\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
        "    return embeddings.detach().numpy()\n",
        "\n",
        "# Apply to your DataFrame\n",
        "df_emojis_train['emoji_embeddings'] = df_emojis_train['emojis'].map(\n",
        "    lambda x: get_emoji_embedding(x, tokenizer, model)\n",
        ")\n",
        "\n",
        "# Display sample embeddings\n",
        "print(df_emojis_train[['emojis', 'emoji_embeddings']].head(15))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:46:39.749751Z",
          "iopub.execute_input": "2025-01-17T09:46:39.750085Z",
          "iopub.status.idle": "2025-01-17T09:47:48.252034Z",
          "shell.execute_reply.started": "2025-01-17T09:46:39.750061Z",
          "shell.execute_reply": "2025-01-17T09:47:48.250816Z"
        },
        "id": "tErTmNOd4rY4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_emojis_train[['emojis', 'emoji_embeddings']].head(75))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:48:46.415096Z",
          "iopub.execute_input": "2025-01-17T09:48:46.415392Z",
          "iopub.status.idle": "2025-01-17T09:48:46.555096Z",
          "shell.execute_reply.started": "2025-01-17T09:48:46.415369Z",
          "shell.execute_reply": "2025-01-17T09:48:46.554353Z"
        },
        "id": "H71uDB1G4rY6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Plotting the distribution of labels in Train, Test, and Validation datasets\n",
        "fig = plt.figure(figsize=(18, 4))\n",
        "titles = ['Train set', 'Test set', 'Val set']\n",
        "\n",
        "for i, dataf in enumerate([df_train, df_test, df_val]):\n",
        "    ax = fig.add_subplot(1, 3, i+1)\n",
        "    Y, labels = pd.factorize(dataf['label'])  # Ensure 'label' column is used\n",
        "    ax.bar(labels, height=pd.Series(Y).value_counts())  # Bar plot for label count\n",
        "    ax.set_xticks(ticks=range(len(labels)))  # Position the x-ticks\n",
        "    ax.set_xticklabels(labels, fontsize=10)  # Set x-tick labels with font size\n",
        "    ax.set_xlabel('Label')  # X-axis label\n",
        "    ax.set_ylabel('Number of examples')  # Y-axis label\n",
        "    ax.set_title(titles[i])  # Title for each plot\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iiVSF8xs0Gz4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:44:26.262419Z",
          "iopub.execute_input": "2025-01-17T09:44:26.262773Z",
          "iopub.status.idle": "2025-01-17T09:44:26.731310Z",
          "shell.execute_reply.started": "2025-01-17T09:44:26.262744Z",
          "shell.execute_reply": "2025-01-17T09:44:26.730311Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of samples in Train, Test, and Validation datasets\n",
        "train_samples = len(df_train)\n",
        "test_samples = len(df_test)\n",
        "val_samples = len(df_val)\n",
        "\n",
        "# Printing the number of samples\n",
        "print(f\"Number of samples in Train set: {train_samples}\")\n",
        "print(f\"Number of samples in Test set: {test_samples}\")\n",
        "print(f\"Number of samples in Validation set: {val_samples}\")\n"
      ],
      "metadata": {
        "id": "OMQsWjS33UDm",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:44:32.114666Z",
          "iopub.execute_input": "2025-01-17T09:44:32.114963Z",
          "iopub.status.idle": "2025-01-17T09:44:32.120716Z",
          "shell.execute_reply.started": "2025-01-17T09:44:32.114939Z",
          "shell.execute_reply": "2025-01-17T09:44:32.119621Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from statistics import mean\n",
        "import pickle\n",
        "from transformers import XLMRobertaTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.optim import SGD"
      ],
      "metadata": {
        "id": "j22YuXdM14i_",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:44:35.970919Z",
          "iopub.execute_input": "2025-01-17T09:44:35.971259Z",
          "iopub.status.idle": "2025-01-17T09:44:38.706076Z",
          "shell.execute_reply.started": "2025-01-17T09:44:35.971229Z",
          "shell.execute_reply": "2025-01-17T09:44:38.705399Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set parameters for fine-tuning\n",
        "L_RATE = 3e-5  # Learning rate\n",
        "MAX_LEN = 128  # Maximum sequence length (adjust according to your dataset)\n",
        "NUM_EPOCHS = 3  # Number of epochs for fine-tuning\n",
        "BATCH_SIZE = 32  # Batch size (can be adjusted based on GPU memory, using 64 if you have sufficient resources)\n",
        "NUM_CORES = os.cpu_count()  # Number of CPU cores available for data processing\n",
        "print(NUM_CORES)  # Print number of cores detected\n",
        "\n",
        "# You can now use these parameters in your fine-tuning script\n"
      ],
      "metadata": {
        "id": "aMn20pj42Dwp",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:44:46.879041Z",
          "iopub.execute_input": "2025-01-17T09:44:46.879632Z",
          "iopub.status.idle": "2025-01-17T09:44:46.884243Z",
          "shell.execute_reply.started": "2025-01-17T09:44:46.879567Z",
          "shell.execute_reply": "2025-01-17T09:44:46.883256Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import XLMRobertaForSequenceClassification\n",
        "\n",
        "# Set device (GPU if available, else CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the XLM-RoBERTa model for sequence classification\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
        "    'xlm-roberta-base',\n",
        "    num_labels=6  # Set the number of labels to 6 (or the number of unique labels in your dataset)\n",
        ")\n",
        "\n",
        "# Move model to the device\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "id": "D3-a0YKM4woW",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:44:51.863162Z",
          "iopub.execute_input": "2025-01-17T09:44:51.863484Z",
          "iopub.status.idle": "2025-01-17T09:44:56.152108Z",
          "shell.execute_reply.started": "2025-01-17T09:44:51.863460Z",
          "shell.execute_reply": "2025-01-17T09:44:56.151179Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "from transformers import XLMRobertaTokenizer\n",
        "\n",
        "# Initialize the tokenizer\n",
        "rTokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "class CompDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self.df_data = df\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.df_data.loc[index, 'cleaned_text']\n",
        "        # Tokenization\n",
        "        encoded_dict = rTokenizer.encode_plus(\n",
        "                    text,\n",
        "                    max_length = MAX_LEN,\n",
        "                    padding='max_length',  # Use padding='max_length' instead of pad_to_max_length\n",
        "                    truncation=True,  # Ensure that the text is truncated if it exceeds MAX_LEN\n",
        "                    return_attention_mask=True,\n",
        "                    return_tensors='pt',\n",
        "               )\n",
        "\n",
        "        padded_token_list = encoded_dict['input_ids'][0]\n",
        "        att_mask = encoded_dict['attention_mask'][0]\n",
        "        target = torch.tensor(self.df_data.loc[index, 'label'])\n",
        "\n",
        "        sample = (padded_token_list, att_mask, target)\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_data)\n"
      ],
      "metadata": {
        "id": "pYMedDZm47Ka",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:45:02.628280Z",
          "iopub.execute_input": "2025-01-17T09:45:02.628969Z",
          "iopub.status.idle": "2025-01-17T09:45:05.057335Z",
          "shell.execute_reply.started": "2025-01-17T09:45:02.628930Z",
          "shell.execute_reply": "2025-01-17T09:45:05.056667Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CompDataset(df_cleaned_text_train)  # Pass your cleaned train DataFrame\n",
        "test_dataset = CompDataset(df_cleaned_text_test)    # Pass your cleaned test DataFrame\n",
        "validation_dataset = CompDataset(df_cleaned_text_val)  # Pass your validation DataFrame"
      ],
      "metadata": {
        "id": "ozUD8tC95LHr",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:45:09.572096Z",
          "iopub.execute_input": "2025-01-17T09:45:09.572385Z",
          "iopub.status.idle": "2025-01-17T09:45:09.576294Z",
          "shell.execute_reply.started": "2025-01-17T09:45:09.572362Z",
          "shell.execute_reply": "2025-01-17T09:45:09.575340Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_dataset))\n",
        "print(len(train_dataset))\n",
        "print(len(validation_dataset))"
      ],
      "metadata": {
        "id": "6vzHJP755Qq0",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:45:13.024419Z",
          "iopub.execute_input": "2025-01-17T09:45:13.024880Z",
          "iopub.status.idle": "2025-01-17T09:45:13.030821Z",
          "shell.execute_reply.started": "2025-01-17T09:45:13.024840Z",
          "shell.execute_reply": "2025-01-17T09:45:13.029920Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def createBaseline(data, name):\n",
        "    # Initialize the dataset and dataloader\n",
        "    test_data = CompDataset(data)\n",
        "    dataloader = torch.utils.data.DataLoader(test_data,\n",
        "                      batch_size=BATCH_SIZE,\n",
        "                      shuffle=False,  # No need to shuffle in the validation or test set\n",
        "                      num_workers=NUM_CORES)\n",
        "\n",
        "    # Set model to evaluation mode and disable gradient computation\n",
        "    model.eval()\n",
        "    torch.set_grad_enabled(False)\n",
        "\n",
        "    # Initialize lists to store the predictions and true labels\n",
        "    targets_list = []\n",
        "    all_preds = []\n",
        "\n",
        "    # Loop over the dataloader to get batches\n",
        "    for j, batch in enumerate(dataloader):\n",
        "        # Move the batch tensors to the device\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Get model predictions\n",
        "        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "        preds = outputs[1]  # Get the logits\n",
        "\n",
        "        # Convert predictions to numpy arrays and store them\n",
        "        val_preds = preds.detach().cpu().numpy()\n",
        "        targets_np = b_labels.to('cpu').numpy()\n",
        "        targets_list.extend(targets_np)\n",
        "\n",
        "        # Accumulate predictions\n",
        "        all_preds.append(val_preds)\n",
        "\n",
        "    # Convert the list of predictions into a single array\n",
        "    stacked_val_preds = np.vstack(all_preds)\n",
        "\n",
        "    # Calculate the predicted labels by taking argmax of logits\n",
        "    y_true = np.array(targets_list)\n",
        "    y_pred = np.argmax(stacked_val_preds, axis=1)\n",
        "\n",
        "    # Compute accuracy and F1 score\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')  # Adding average='weighted' for handling class imbalance\n",
        "\n",
        "    # Print results\n",
        "    print(f\"{name} test acc: {acc:.4f}\")\n",
        "    print(f\"{name} test F1: {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "K6Hn1ypV5ewC",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:45:16.328730Z",
          "iopub.execute_input": "2025-01-17T09:45:16.329086Z",
          "iopub.status.idle": "2025-01-17T09:45:16.336633Z",
          "shell.execute_reply.started": "2025-01-17T09:45:16.329055Z",
          "shell.execute_reply": "2025-01-17T09:45:16.335491Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "createBaseline(df_cleaned_text_test, \"tamil\")"
      ],
      "metadata": {
        "id": "HccKOpIo5qJ2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:45:22.338042Z",
          "iopub.execute_input": "2025-01-17T09:45:22.338346Z",
          "iopub.status.idle": "2025-01-17T09:45:41.928312Z",
          "shell.execute_reply.started": "2025-01-17T09:45:22.338323Z",
          "shell.execute_reply": "2025-01-17T09:45:41.927252Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import gc"
      ],
      "metadata": {
        "id": "0kjhgNov6BEN",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:45:45.683972Z",
          "iopub.execute_input": "2025-01-17T09:45:45.684286Z",
          "iopub.status.idle": "2025-01-17T09:45:45.688442Z",
          "shell.execute_reply.started": "2025-01-17T09:45:45.684256Z",
          "shell.execute_reply": "2025-01-17T09:45:45.687474Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.parameters())"
      ],
      "metadata": {
        "id": "W_M4KLDc6B-1",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:45:50.011112Z",
          "iopub.execute_input": "2025-01-17T09:45:50.011404Z",
          "iopub.status.idle": "2025-01-17T09:45:50.016279Z",
          "shell.execute_reply.started": "2025-01-17T09:45:50.011381Z",
          "shell.execute_reply": "2025-01-17T09:45:50.015164Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "              lr = L_RATE,\n",
        "              eps = 1e-8\n",
        "            )"
      ],
      "metadata": {
        "id": "paLFThgG6EOX",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:45:53.400790Z",
          "iopub.execute_input": "2025-01-17T09:45:53.401130Z",
          "iopub.status.idle": "2025-01-17T09:45:53.409625Z",
          "shell.execute_reply.started": "2025-01-17T09:45:53.401108Z",
          "shell.execute_reply": "2025-01-17T09:45:53.408663Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = CompDataset(df_cleaned_text_train)\n",
        "val_data = CompDataset(df_cleaned_text_val)"
      ],
      "metadata": {
        "id": "7emn4zet6HH9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:45:56.834028Z",
          "iopub.execute_input": "2025-01-17T09:45:56.834317Z",
          "iopub.status.idle": "2025-01-17T09:45:56.838257Z",
          "shell.execute_reply.started": "2025-01-17T09:45:56.834295Z",
          "shell.execute_reply": "2025-01-17T09:45:56.837256Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(train_data,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    shuffle=True,\n",
        "                    num_workers=NUM_CORES)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_data,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    shuffle=True,\n",
        "                    num_workers=NUM_CORES)"
      ],
      "metadata": {
        "id": "Hq31Sl1gCXyO",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:45:59.274103Z",
          "iopub.execute_input": "2025-01-17T09:45:59.274386Z",
          "iopub.status.idle": "2025-01-17T09:45:59.278646Z",
          "shell.execute_reply.started": "2025-01-17T09:45:59.274363Z",
          "shell.execute_reply": "2025-01-17T09:45:59.277691Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "1TG_ftapCbqM",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:46:02.432136Z",
          "iopub.execute_input": "2025-01-17T09:46:02.432484Z",
          "iopub.status.idle": "2025-01-17T09:46:02.772855Z",
          "shell.execute_reply.started": "2025-01-17T09:46:02.432451Z",
          "shell.execute_reply": "2025-01-17T09:46:02.771855Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import gc\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "seed_val = 101\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "loss_values = []\n",
        "\n",
        "# Define your number of epochs\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "for epoch in range(0, NUM_EPOCHS):\n",
        "\n",
        "    print(\"\\n======== Epoch {:} / {:} ========\".format(epoch + 1, NUM_EPOCHS))\n",
        "\n",
        "    stacked_val_labels = []\n",
        "    targets_list = []\n",
        "\n",
        "    # Training Phase\n",
        "    print('Training...')\n",
        "    model.train()\n",
        "    torch.set_grad_enabled(True)\n",
        "    total_train_loss = 0\n",
        "    gc.collect()\n",
        "\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        model.zero_grad()\n",
        "        outputs = model(b_input_ids,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        total_train_loss += loss.item()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Clip gradients\n",
        "        optimizer.step()  # Update model weights\n",
        "        gc.collect()\n",
        "\n",
        "    print('Train loss:', total_train_loss)\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    # Validation Phase\n",
        "    print('\\nValidation...')\n",
        "    model.eval()\n",
        "    torch.set_grad_enabled(False)\n",
        "    total_val_loss = 0\n",
        "    for j, batch in enumerate(val_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        outputs = model(b_input_ids,\n",
        "                        attention_mask=b_input_mask,\n",
        "                        labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        total_val_loss += loss.item()\n",
        "        preds = outputs[1]\n",
        "        val_preds = preds.detach().cpu().numpy()\n",
        "        targets_np = b_labels.to('cpu').numpy()\n",
        "        targets_list.extend(targets_np)\n",
        "        if j == 0:\n",
        "            stacked_val_preds = val_preds\n",
        "        else:\n",
        "            stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n",
        "        gc.collect()\n",
        "\n",
        "    y_true = targets_list\n",
        "    y_pred = np.argmax(stacked_val_preds, axis=1)\n",
        "    val_acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    print('Val loss:', total_val_loss)\n",
        "    print('Val acc:', val_acc)\n",
        "    print('Val f1:', f1)\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    # Save model weights after each epoch\n",
        "    torch.save(model.state_dict(), 'model.pt')\n",
        "\n",
        "    gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srKH3YwbCeP0",
        "outputId": "c6754465-9e7e-4b47-b00e-ea4605f40d62",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T09:34:04.510557Z",
          "iopub.execute_input": "2025-01-17T09:34:04.510839Z"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n",
            "Train loss: 827.8175112307072\n",
            "\n",
            "Validation...\n",
            "Val loss: 100.7767343223095\n",
            "Val acc: 0.7525068368277119\n",
            "Val f1: 0.7054498315817483\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n",
            "Train loss: 697.4605175852776\n",
            "\n",
            "Validation...\n",
            "Val loss: 95.77813732624054\n",
            "Val acc: 0.7750683682771194\n",
            "Val f1: 0.7199594273991753\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n",
            "Train loss: 639.9167290627956\n",
            "\n",
            "Validation...\n",
            "Val loss: 97.17093622684479\n",
            "Val acc: 0.7700546946216955\n",
            "Val f1: 0.7299381458719041\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import torch\n",
        "\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            _, predicted = torch.max(logits, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    precision = precision_score(all_labels, all_predictions, average='weighted')\n",
        "    recall = recall_score(all_labels, all_predictions, average='weighted')\n",
        "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1_score\": f1}\n"
      ],
      "metadata": {
        "id": "JXqoiOSH5A2Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}