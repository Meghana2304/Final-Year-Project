{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e233d113f20d41a8a0c0540eb70b164d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f37b4feb0dfb4406980578200998f3af","IPY_MODEL_44c740433b7c4e41b514da87cba4c0a2","IPY_MODEL_bef7e38b78be47768bfa6035e8f42ce9"],"layout":"IPY_MODEL_d3500be08fce4112bb17721bfa560d99"}},"f37b4feb0dfb4406980578200998f3af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc62d0e3225646f180e82c6a16d88d54","placeholder":"​","style":"IPY_MODEL_a38d3b8bba07436bb9d399a9151989d1","value":"README.md: 100%"}},"44c740433b7c4e41b514da87cba4c0a2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_94a4020044df4092a923532a27aa1e73","max":15485,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7928b0d1043b41768ff92b836622771d","value":15485}},"bef7e38b78be47768bfa6035e8f42ce9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_202ac3f24200484fa8e139ee4baae641","placeholder":"​","style":"IPY_MODEL_b73ea9e91676425690da926f663b36d7","value":" 15.5k/15.5k [00:00&lt;00:00, 529kB/s]"}},"d3500be08fce4112bb17721bfa560d99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc62d0e3225646f180e82c6a16d88d54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a38d3b8bba07436bb9d399a9151989d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94a4020044df4092a923532a27aa1e73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7928b0d1043b41768ff92b836622771d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"202ac3f24200484fa8e139ee4baae641":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b73ea9e91676425690da926f663b36d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44d8eaed7c874596a99917dfd6987fdf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d71a7250312a465e8b56607247376d5c","IPY_MODEL_d197385570704274a5ae18d3214f5a25","IPY_MODEL_ebf7fb6285934aad907e69533a6fc82a"],"layout":"IPY_MODEL_cf1dbde5e74d41acae107dae73ae06ef"}},"d71a7250312a465e8b56607247376d5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbdec4658705449c8d877f1bbda4f8cf","placeholder":"​","style":"IPY_MODEL_00ee744b6025492b8a336d7aba1a7145","value":"train-00000-of-00001.parquet: 100%"}},"d197385570704274a5ae18d3214f5a25":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_43f1dfa282b44212ae4f572c2e949bc5","max":2392028,"min":0,"orientation":"horizontal","style":"IPY_MODEL_92d81d8b28464e898e6f3392a679b623","value":2392028}},"ebf7fb6285934aad907e69533a6fc82a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24282d2da3cc4024a168de171e82f322","placeholder":"​","style":"IPY_MODEL_980d798e27ee449f8c524e89f3929cea","value":" 2.39M/2.39M [00:00&lt;00:00, 23.6MB/s]"}},"cf1dbde5e74d41acae107dae73ae06ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbdec4658705449c8d877f1bbda4f8cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00ee744b6025492b8a336d7aba1a7145":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43f1dfa282b44212ae4f572c2e949bc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92d81d8b28464e898e6f3392a679b623":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"24282d2da3cc4024a168de171e82f322":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"980d798e27ee449f8c524e89f3929cea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"104aa6101ed94a328d293462edd7b812":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36eefeb327aa405bb69f2a0ce98c2d17","IPY_MODEL_309bb375ce434d10b2a6b60b2cffbafd","IPY_MODEL_614b10ea5899410f93331a86ac3abd08"],"layout":"IPY_MODEL_56ea54ca57fd4b63aa31c2183ca3fe4f"}},"36eefeb327aa405bb69f2a0ce98c2d17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5603d5b197564eb297385573c5b09178","placeholder":"​","style":"IPY_MODEL_a02d51d46a6343c59c22e3783ca7ff00","value":"validation-00000-of-00001.parquet: 100%"}},"309bb375ce434d10b2a6b60b2cffbafd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2f300db63e3463fb28f3d676fb9d5b6","max":298034,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1dce75fb9fb34d2b9f8d8ed462c9ef80","value":298034}},"614b10ea5899410f93331a86ac3abd08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00e2ea8dc93e4760ac56b9df7bfc17b3","placeholder":"​","style":"IPY_MODEL_0b39f65d3b974c06b6512ef11138831c","value":" 298k/298k [00:00&lt;00:00, 8.79MB/s]"}},"56ea54ca57fd4b63aa31c2183ca3fe4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5603d5b197564eb297385573c5b09178":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a02d51d46a6343c59c22e3783ca7ff00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2f300db63e3463fb28f3d676fb9d5b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1dce75fb9fb34d2b9f8d8ed462c9ef80":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"00e2ea8dc93e4760ac56b9df7bfc17b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b39f65d3b974c06b6512ef11138831c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"416e30395f784c6faa7cb044a4c2ea99":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_74a40faf9fcd471e91638dbeb1b21133","IPY_MODEL_201c986675de4cc8860d6562377ee12a","IPY_MODEL_1b44c5f8abf34c4bb973d8393682243b"],"layout":"IPY_MODEL_e037d711ae6a46bb9a0adbbb447077cd"}},"74a40faf9fcd471e91638dbeb1b21133":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fb665c69ebd4fa5a3f142aa287f0f14","placeholder":"​","style":"IPY_MODEL_cedaf2e809ce4394ac94d9c848e89359","value":"Generating train split: 100%"}},"201c986675de4cc8860d6562377ee12a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e28c953eea9246c08badff7caad160ca","max":35139,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1db568dddc484ef3bb4ad83d9aee73b9","value":35139}},"1b44c5f8abf34c4bb973d8393682243b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76d92b92916b41a4bdbe35144a511efe","placeholder":"​","style":"IPY_MODEL_6d47e5711fad499396e05a6f4df0e2d5","value":" 35139/35139 [00:00&lt;00:00, 186157.03 examples/s]"}},"e037d711ae6a46bb9a0adbbb447077cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fb665c69ebd4fa5a3f142aa287f0f14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cedaf2e809ce4394ac94d9c848e89359":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e28c953eea9246c08badff7caad160ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1db568dddc484ef3bb4ad83d9aee73b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"76d92b92916b41a4bdbe35144a511efe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d47e5711fad499396e05a6f4df0e2d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87d287a551284b9abd7b11a5a4255379":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c5406ab79c774cb49d896a829d101750","IPY_MODEL_dfa0c7d8031b45019461552c93926de0","IPY_MODEL_062c51ccf4764834ac666d34b019bd81"],"layout":"IPY_MODEL_c27510cbc3af4b25bc3c05af1c0f844f"}},"c5406ab79c774cb49d896a829d101750":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88a2f9288e154e878da0a9a1063d9dc0","placeholder":"​","style":"IPY_MODEL_c82095bd755148788ca51812791498b1","value":"Generating validation split: 100%"}},"dfa0c7d8031b45019461552c93926de0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_784cc48890e64a08aba32eab69e08e19","max":4388,"min":0,"orientation":"horizontal","style":"IPY_MODEL_590b105147904f4d8f0fa903fdd64929","value":4388}},"062c51ccf4764834ac666d34b019bd81":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c927a7cff5b94ab6af3b4a596a74a94b","placeholder":"​","style":"IPY_MODEL_5e7d90417c654e8ca78c013ef7a32928","value":" 4388/4388 [00:00&lt;00:00, 52479.33 examples/s]"}},"c27510cbc3af4b25bc3c05af1c0f844f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88a2f9288e154e878da0a9a1063d9dc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c82095bd755148788ca51812791498b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"784cc48890e64a08aba32eab69e08e19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"590b105147904f4d8f0fa903fdd64929":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c927a7cff5b94ab6af3b4a596a74a94b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e7d90417c654e8ca78c013ef7a32928":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"__tE4n2VEhph","outputId":"bdc2fc84-84e8-4ade-9f14-07680aa2eea9","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install pandas","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J1W5_sJPuPYU","outputId":"cc142bb5-bc06-4bd4-c5ea-ce9356170594","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset(\"community-datasets/offenseval_dravidian\", \"tamil\")\n\nprint(dataset)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455,"referenced_widgets":["e233d113f20d41a8a0c0540eb70b164d","f37b4feb0dfb4406980578200998f3af","44c740433b7c4e41b514da87cba4c0a2","bef7e38b78be47768bfa6035e8f42ce9","d3500be08fce4112bb17721bfa560d99","fc62d0e3225646f180e82c6a16d88d54","a38d3b8bba07436bb9d399a9151989d1","94a4020044df4092a923532a27aa1e73","7928b0d1043b41768ff92b836622771d","202ac3f24200484fa8e139ee4baae641","b73ea9e91676425690da926f663b36d7","44d8eaed7c874596a99917dfd6987fdf","d71a7250312a465e8b56607247376d5c","d197385570704274a5ae18d3214f5a25","ebf7fb6285934aad907e69533a6fc82a","cf1dbde5e74d41acae107dae73ae06ef","dbdec4658705449c8d877f1bbda4f8cf","00ee744b6025492b8a336d7aba1a7145","43f1dfa282b44212ae4f572c2e949bc5","92d81d8b28464e898e6f3392a679b623","24282d2da3cc4024a168de171e82f322","980d798e27ee449f8c524e89f3929cea","104aa6101ed94a328d293462edd7b812","36eefeb327aa405bb69f2a0ce98c2d17","309bb375ce434d10b2a6b60b2cffbafd","614b10ea5899410f93331a86ac3abd08","56ea54ca57fd4b63aa31c2183ca3fe4f","5603d5b197564eb297385573c5b09178","a02d51d46a6343c59c22e3783ca7ff00","f2f300db63e3463fb28f3d676fb9d5b6","1dce75fb9fb34d2b9f8d8ed462c9ef80","00e2ea8dc93e4760ac56b9df7bfc17b3","0b39f65d3b974c06b6512ef11138831c","416e30395f784c6faa7cb044a4c2ea99","74a40faf9fcd471e91638dbeb1b21133","201c986675de4cc8860d6562377ee12a","1b44c5f8abf34c4bb973d8393682243b","e037d711ae6a46bb9a0adbbb447077cd","9fb665c69ebd4fa5a3f142aa287f0f14","cedaf2e809ce4394ac94d9c848e89359","e28c953eea9246c08badff7caad160ca","1db568dddc484ef3bb4ad83d9aee73b9","76d92b92916b41a4bdbe35144a511efe","6d47e5711fad499396e05a6f4df0e2d5","87d287a551284b9abd7b11a5a4255379","c5406ab79c774cb49d896a829d101750","dfa0c7d8031b45019461552c93926de0","062c51ccf4764834ac666d34b019bd81","c27510cbc3af4b25bc3c05af1c0f844f","88a2f9288e154e878da0a9a1063d9dc0","c82095bd755148788ca51812791498b1","784cc48890e64a08aba32eab69e08e19","590b105147904f4d8f0fa903fdd64929","c927a7cff5b94ab6af3b4a596a74a94b","5e7d90417c654e8ca78c013ef7a32928"]},"id":"MX6RAU53sUlf","outputId":"a5084f2d-e613-4b44-ca10-6c0eae3602bf","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\nimport re\nfrom sklearn.model_selection import train_test_split\n\n# Load the dataset\ndataset = load_dataset(\"community-datasets/offenseval_dravidian\", \"tamil\")\n\n# Convert the dataset to a list of dictionaries so train_test_split can be applied\ntrain_data = dataset['train']\n\n# Convert the dataset to a list of dicts (this step should be done carefully)\ntrain_data_list = [{'text': item['text'], 'label': item['label']} for item in train_data]\n\n# Split the train data into 90% for training and 10% for testing\ntrain_data_split, test_data_split = train_test_split(train_data_list, test_size=0.1, random_state=42)\n\n# Clean function to preserve emojis and emoticons\ndef clean_text(text):\n    # Remove unwanted characters but keep emojis and emoticons\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  # Remove URLs\n    # Keep only letters, numbers, whitespaces, and emojis\n    text = re.sub(r'[^a-zA-Z0-9\\s\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U000024C2-\\U0001F251]', '', text)\n    text = text.strip()\n    return text\n\n# Apply the cleaning function to the train, test, and validation datasets\ntrain_data_split = [{'text': clean_text(item['text']), 'label': item['label']} for item in train_data_split]\ntest_data_split = [{'text': clean_text(item['text']), 'label': item['label']} for item in test_data_split]\ndataset['validation'] = [{'text': clean_text(item['text']), 'label': item['label']} for item in dataset['validation']]\n\n# Check the cleaned data\nprint(train_data_split[1])\nprint(test_data_split[0])\nprint(dataset['validation'][0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L25cyOVXuSf-","outputId":"bd7425d7-2298-4ebf-d7dc-e15f38e79ccd","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom datasets import load_dataset\n\n# Load the dataset\ndataset = load_dataset(\"community-datasets/offenseval_dravidian\", \"tamil\")\n\n# Extract train data\ntrain_data = dataset['train']\n\n# Convert to a list of dictionaries for train_test_split\ntrain_data_list = [{'text': item['text'], 'label': item['label']} for item in train_data]\n\n# Split train data into 90% train and 10% test\ntrain_data_split, test_data_split = train_test_split(train_data_list, test_size=0.1, random_state=42)\n\n# Convert lists of dictionaries to pandas DataFrames\ndf_train = pd.DataFrame(train_data_split)\ndf_test = pd.DataFrame(test_data_split)\ndf_val = pd.DataFrame([{'text': item['text'], 'label': item['label']} for item in dataset['validation']])\n\n# Ensure the DataFrames contain the required columns\nrequired_columns = ['text', 'label']\nfor df_name, df in zip(['df_train', 'df_test', 'df_val'], [df_train, df_test, df_val]):\n    if not all(col in df.columns for col in required_columns):\n        raise KeyError(f\"{df_name} must contain the columns {required_columns}.\")\n\n# Function to extract emojis from the text\ndef extract_emojis(text):\n    emoji_pattern = re.compile(\n        r'[\\U0001F600-\\U0001F64F'  # emoticons\n        r'\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n        r'\\U0001F680-\\U0001F6FF'  # transport & map symbols\n        r'\\U0001F700-\\U0001F77F'  # alchemical symbols\n        r'\\U0001F780-\\U0001F7FF'  # Geometric Shapes Extended\n        r'\\U0001F800-\\U0001F8FF'  # Supplemental Arrows-C\n        r'\\U0001F900-\\U0001F9FF'  # Supplemental Symbols and Pictographs\n        r'\\U0001FA00-\\U0001FA6F'  # Chess Symbols\n        r'\\U0001FA70-\\U0001FAFF'  # Symbols and Pictographs Extended-A\n        r'\\U00002702-\\U000027B0'  # Dingbats\n        r'\\U000024C2-\\U0001F251'  # Enclosed characters\n        r']+', flags=re.UNICODE)\n    emojis = emoji_pattern.findall(text)\n    return ''.join(emojis)\n\n# Function to separate emojis and clean text\ndef separate_emojis(text):\n    emojis = extract_emojis(text)\n    # Remove emojis and keep only cleaned text\n    text_without_emojis = re.sub(r'[^\\w\\s,\\.!?]', '', text)\n    return text_without_emojis.strip(), emojis\n\n# Apply the cleaning and emoji extraction function\ndf_train['cleaned_text'], df_train['emojis'] = zip(*df_train['text'].map(separate_emojis))\ndf_test['cleaned_text'], df_test['emojis'] = zip(*df_test['text'].map(separate_emojis))\ndf_val['cleaned_text'], df_val['emojis'] = zip(*df_val['text'].map(separate_emojis))\n\n# Create separate DataFrames for cleaned text and emojis with labels\ndf_cleaned_text_train = df_train[['cleaned_text', 'label']].copy()\ndf_emojis_train = df_train[['emojis', 'label']].copy()\n\ndf_cleaned_text_test = df_test[['cleaned_text', 'label']].copy()\ndf_emojis_test = df_test[['emojis', 'label']].copy()\n\ndf_cleaned_text_val = df_val[['cleaned_text', 'label']].copy()\ndf_emojis_val = df_val[['emojis', 'label']].copy()\n\n# Display sample data\nprint(\"Cleaned Text Train Data:\")\nprint(df_cleaned_text_train.head())\n\nprint(\"\\nEmojis Train Data:\")\nprint(df_emojis_train.head())\n\nprint(\"\\nCleaned Text Test Data:\")\nprint(df_cleaned_text_test.head())\n\nprint(\"\\nEmojis Test Data:\")\nprint(df_emojis_test.head())\n\nprint(\"\\nCleaned Text Validation Data:\")\nprint(df_cleaned_text_val.head())\n\nprint(\"\\nEmojis Validation Data:\")\nprint(df_emojis_val.head())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FPJL_RJo3EyS","outputId":"e02a0aa9-72ee-4609-97cd-0f6a01a88bf0","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nimport torch\n\n# Load a pre-trained model and tokenizer\nmodel_name = \"bert-base-uncased\"  # Replace with a model fine-tuned for emojis if needed\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModel.from_pretrained(model_name)\n\n# Function to get embeddings for emojis\ndef get_emoji_embedding(emojis, tokenizer, model):\n    if not emojis:  # No emojis provided\n        return torch.zeros(768)  # Assuming the model outputs 768-dimensional embeddings\n    inputs = tokenizer(emojis, return_tensors=\"pt\", truncation=True, max_length=10)\n    outputs = model(**inputs)\n    # Use the mean of the last hidden state as the embedding\n    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze()\n    return embeddings.detach().numpy()\n\n# Apply to your DataFrame\ndf_emojis_train['emoji_embeddings'] = df_emojis_train['emojis'].map(\n    lambda x: get_emoji_embedding(x, tokenizer, model)\n)\n\n# Display sample embeddings\nprint(df_emojis_train[['emojis', 'emoji_embeddings']].head(15))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df_emojis_train[['emojis', 'emoji_embeddings']].head(75))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\n\n# Plotting the distribution of labels in Train, Test, and Validation datasets\nfig = plt.figure(figsize=(18, 4))\ntitles = ['Train set', 'Test set', 'Val set']\n\nfor i, dataf in enumerate([df_train, df_test, df_val]):\n    ax = fig.add_subplot(1, 3, i+1)\n    Y, labels = pd.factorize(dataf['label'])  # Ensure 'label' column is used\n    ax.bar(labels, height=pd.Series(Y).value_counts())  # Bar plot for label count\n    ax.set_xticks(ticks=range(len(labels)))  # Position the x-ticks\n    ax.set_xticklabels(labels, fontsize=10)  # Set x-tick labels with font size\n    ax.set_xlabel('Label')  # X-axis label\n    ax.set_ylabel('Number of examples')  # Y-axis label\n    ax.set_title(titles[i])  # Title for each plot\n\n# Show the plots\nplt.tight_layout()\nplt.show()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":327},"id":"iiVSF8xs0Gz4","outputId":"4bf1cb89-83b0-4bca-dafe-82b40e4afb80","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Number of samples in Train, Test, and Validation datasets\ntrain_samples = len(df_train)\ntest_samples = len(df_test)\nval_samples = len(df_val)\n\n# Printing the number of samples\nprint(f\"Number of samples in Train set: {train_samples}\")\nprint(f\"Number of samples in Test set: {test_samples}\")\nprint(f\"Number of samples in Validation set: {val_samples}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OMQsWjS33UDm","outputId":"b5333de3-1ac9-4e27-f1ca-5635b9682fe1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom statistics import mean\nimport pickle\nfrom transformers import XLMRobertaTokenizer, AdamW, get_linear_schedule_with_warmup\nfrom torch.optim import SGD","metadata":{"id":"j22YuXdM14i_","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Set parameters for fine-tuning\nL_RATE = 3e-5  # Learning rate\nMAX_LEN = 128  # Maximum sequence length (adjust according to your dataset)\nNUM_EPOCHS = 3  # Number of epochs for fine-tuning\nBATCH_SIZE = 32  # Batch size (can be adjusted based on GPU memory, using 64 if you have sufficient resources)\nNUM_CORES = os.cpu_count()  # Number of CPU cores available for data processing\nprint(NUM_CORES)  # Print number of cores detected\n\n# You can now use these parameters in your fine-tuning script\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aMn20pj42Dwp","outputId":"37f2b8cc-6515-4166-cda5-49f31a76acac","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import XLMRobertaForSequenceClassification\n\n# Set device (GPU if available, else CPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load the XLM-RoBERTa model for sequence classification\nmodel = XLMRobertaForSequenceClassification.from_pretrained(\n    'xlm-roberta-base',\n    num_labels=6  # Set the number of labels to 6 (or the number of unique labels in your dataset)\n)\n\n# Move model to the device\nmodel.to(device)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D3-a0YKM4woW","outputId":"3faf2f7f-8fe3-4f49-b62f-5b8bee22ee16","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport torch\nfrom transformers import XLMRobertaTokenizer\n\n# Initialize the tokenizer\nrTokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")\n\nclass CompDataset(Dataset):\n\n    def __init__(self, df):\n        self.df_data = df\n\n    def __getitem__(self, index):\n        text = self.df_data.loc[index, 'cleaned_text']\n        # Tokenization\n        encoded_dict = rTokenizer.encode_plus(\n                    text,\n                    max_length = MAX_LEN,\n                    padding='max_length',  # Use padding='max_length' instead of pad_to_max_length\n                    truncation=True,  # Ensure that the text is truncated if it exceeds MAX_LEN\n                    return_attention_mask=True,\n                    return_tensors='pt',\n               )\n\n        padded_token_list = encoded_dict['input_ids'][0]\n        att_mask = encoded_dict['attention_mask'][0]\n        target = torch.tensor(self.df_data.loc[index, 'label'])\n\n        sample = (padded_token_list, att_mask, target)\n        return sample\n\n    def __len__(self):\n        return len(self.df_data)\n","metadata":{"id":"pYMedDZm47Ka","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = CompDataset(df_cleaned_text_train)  # Pass your cleaned train DataFrame\ntest_dataset = CompDataset(df_cleaned_text_test)    # Pass your cleaned test DataFrame\nvalidation_dataset = CompDataset(df_cleaned_text_val)  # Pass your validation DataFrame","metadata":{"id":"ozUD8tC95LHr","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(test_dataset))\nprint(len(train_dataset))\nprint(len(validation_dataset))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6vzHJP755Qq0","outputId":"864c426e-3cb9-4b6b-ab8b-0f62dbdc5f86","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\ndef createBaseline(data, name):\n    # Initialize the dataset and dataloader\n    test_data = CompDataset(data)\n    dataloader = torch.utils.data.DataLoader(test_data,\n                      batch_size=BATCH_SIZE,\n                      shuffle=False,  # No need to shuffle in the validation or test set\n                      num_workers=NUM_CORES)\n\n    # Set model to evaluation mode and disable gradient computation\n    model.eval()\n    torch.set_grad_enabled(False)\n\n    # Initialize lists to store the predictions and true labels\n    targets_list = []\n    all_preds = []\n\n    # Loop over the dataloader to get batches\n    for j, batch in enumerate(dataloader):\n        # Move the batch tensors to the device\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n\n        # Get model predictions\n        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n        preds = outputs[1]  # Get the logits\n\n        # Convert predictions to numpy arrays and store them\n        val_preds = preds.detach().cpu().numpy()\n        targets_np = b_labels.to('cpu').numpy()\n        targets_list.extend(targets_np)\n\n        # Accumulate predictions\n        all_preds.append(val_preds)\n\n    # Convert the list of predictions into a single array\n    stacked_val_preds = np.vstack(all_preds)\n\n    # Calculate the predicted labels by taking argmax of logits\n    y_true = np.array(targets_list)\n    y_pred = np.argmax(stacked_val_preds, axis=1)\n\n    # Compute accuracy, precision, recall, and F1 score\n    acc = accuracy_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred, average='weighted')\n    recall = recall_score(y_true, y_pred, average='weighted')\n    f1 = f1_score(y_true, y_pred, average='weighted')  # Adding average='weighted' for handling class imbalance\n\n    # Print results\n    print(f\"{name} test acc: {acc:.4f}\")\n    print(f\"{name} test precision: {precision:.4f}\")\n    print(f\"{name} test recall: {recall:.4f}\")\n    print(f\"{name} test F1: {f1:.4f}\")","metadata":{"id":"K6Hn1ypV5ewC","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"createBaseline(df_cleaned_text_test, \"tamil\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HccKOpIo5qJ2","outputId":"00470840-332d-438f-a668-a6b459a1bbd4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nimport gc","metadata":{"id":"0kjhgNov6BEN","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(model.parameters())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W_M4KLDc6B-1","outputId":"b764222f-a078-4ad4-ecdf-441482e0cc15","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(),\n              lr = L_RATE,\n              eps = 1e-8\n            )","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"paLFThgG6EOX","outputId":"987d5d25-cfd3-4bd5-fcc8-020cdf001114","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = CompDataset(df_cleaned_text_train)\nval_data = CompDataset(df_cleaned_text_val)","metadata":{"id":"7emn4zet6HH9","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataloader = torch.utils.data.DataLoader(train_data,\n                    batch_size=BATCH_SIZE,\n                    shuffle=True,\n                    num_workers=NUM_CORES)\nval_dataloader = torch.utils.data.DataLoader(val_data,\n                    batch_size=BATCH_SIZE,\n                    shuffle=True,\n                    num_workers=NUM_CORES)","metadata":{"id":"Hq31Sl1gCXyO","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gc.collect()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1TG_ftapCbqM","outputId":"1def59c8-67cb-4905-c29a-908c9209175b","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport random\nimport numpy as np\nimport gc\nfrom sklearn.metrics import accuracy_score, f1_score\n\nseed_val = 101\n\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\nloss_values = []\n\n# Define your number of epochs\nNUM_EPOCHS = 3\n\nfor epoch in range(0, NUM_EPOCHS):\n\n    print(\"\\n======== Epoch {:} / {:} ========\".format(epoch + 1, NUM_EPOCHS))\n\n    stacked_val_labels = []\n    targets_list = []\n\n    # Training Phase\n    print('Training...')\n    model.train()\n    torch.set_grad_enabled(True)\n    total_train_loss = 0\n    gc.collect()\n\n    for i, batch in enumerate(train_dataloader):\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        model.zero_grad()\n        outputs = model(b_input_ids,\n                        attention_mask=b_input_mask,\n                        labels=b_labels)\n        loss = outputs[0]\n        total_train_loss += loss.item()\n        optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Clip gradients\n        optimizer.step()  # Update model weights\n        gc.collect()\n\n    print('Train loss:', total_train_loss)\n\n    gc.collect()\n\n    # Validation Phase\n    print('\\nValidation...')\n    model.eval()\n    torch.set_grad_enabled(False)\n    total_val_loss = 0\n    for j, batch in enumerate(val_dataloader):\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        outputs = model(b_input_ids,\n                        attention_mask=b_input_mask,\n                        labels=b_labels)\n        loss = outputs[0]\n        total_val_loss += loss.item()\n        preds = outputs[1]\n        val_preds = preds.detach().cpu().numpy()\n        targets_np = b_labels.to('cpu').numpy()\n        targets_list.extend(targets_np)\n        if j == 0:\n            stacked_val_preds = val_preds\n        else:\n            stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n        gc.collect()\n\n    y_true = targets_list\n    y_pred = np.argmax(stacked_val_preds, axis=1)\n    val_acc = accuracy_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred, average='weighted')\n    print('Val loss:', total_val_loss)\n    print('Val acc:', val_acc)\n    print('Val f1:', f1)\n\n    gc.collect()\n\n    # Save model weights after each epoch\n    torch.save(model.state_dict(), 'model.pt')\n\n    gc.collect()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"srKH3YwbCeP0","outputId":"7d0a3ef1-e5f4-4f4b-e9de-656ffcfee8ac","trusted":true},"outputs":[],"execution_count":null}]}